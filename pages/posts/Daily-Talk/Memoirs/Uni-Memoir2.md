---
title: 大二回忆录
excerpt: 我的大二生活。
date: 2024-11-23 20:41:00+0800
image: https://pic.axi404.top/123626311_p0.1ziagl1oxc.webp
categories:
    - 'Daily Talk'
    - Memoirs
tags:
    - 'Daily Talk'
    - University
    - Memoir
top: 1       # You can add weight to some posts to override the default sorting (date descending)
---

随着今年的 CVPR 的投稿来到了尾声，随着补充材料的提交，可以说给这一段经历画下来一个短暂的逗号，之后，我还会继续在上海进行科研，但是至少在现在来看，还是可以终于有一点点时间，来记录一下很久就想做的大二回忆录。

## 前路茫茫

在度过了繁忙的大一之后，相较于刚刚入学时候的我，我的个人水平可以说已经有了长足的进步。我现在不只是掌握了很多编程语言，同时也参与了 RM 这种中型体量的代码工程，而同时我也学习了机器学习和深度学习的常识知识，包括那几本脍炙人口的书籍，以及大约五十篇的论文。

在 WJH 学长的引领下，我认识了绿群，并且开始了新的一段水群之旅，开始有意识的规划自己将来的保研。一开始我的目的就是很明确的，在经历了一些论文阅读之后，加上和一些其他人的聊天，我可以确定一个初步的想法，那就是在短时间内我是喜欢科研的，并且打算将学术作为自己的第一发展方向，换句话说，对于我来说最好的途径，就是加入课题组并且参加科研，然后通过论文发表来获得清北华五级别学校的 PhD offer。

在和学长进行的简单的咨询之后，我就快速地选择了周三平老师作为我的第一位导师。

讲实话，我在当时有一些考量，从兴趣上来说，我之前是抽空看过 Games 101，对于计算机图形学非常感兴趣，然而这并非潮流，就像我对前端开发很感兴趣一样，我可以有很多感兴趣的事情，但是我需要从里面选择出来那一个，我又有兴趣，又可以给我带来更好的发展的方向。在西交人机所（也就是人工智能学院），做计算机图形学的只有一位老师，而我对于计算机学院也不太了解，所以也就放弃了选择。

通过和学长的交流，我了解到了人机所比较有潜力和水平的几位老师，我向其中的两位老师发了邮件，周三平老师立刻就回复我了，另一位老师则了无音讯（后面有一位同学委托班主任搭桥，进入了这名老师的课题组，结果却是做了标注数据集的杂活，也可以说，冥冥中都是命运的安排吧）。我按照学长交给我的办法，在谷歌学术上看了老师的发表，当时我其实还并不清楚，事实上挂了老师名字的论文，有很多都其实并不属于这位老师直属的课题组，所以看到了其中我比较感兴趣的图像修复（我实际上更加感兴趣的是图像生成，当时并不了解这方面详细的技术背景，但是类似于 DDPM 以及后续工作的一些论文倒是看过，对于那些算法十分感兴趣，但没有发现老师有相关的背景，就只能退而求其次）。

可以说当时我还是比较害怕，不知道自己是不是有资格进行科研，所以还是等到了奖学金的排名公布之后，我才好意思发出邮件，而这个时候已经十月初了。我和老师进行了一次快速的面试，或者说就是在一起聊了一下，我和老师说了我的兴趣，但老师告诉我这方面他已经不再做了，不过可以和另外两个已经大三的学长一起做医学影像相关的内容。我对医学影像并不是很感兴趣，不过感觉也是可以做一下的，就答应了下来。老师给了我一篇论文，让我看一看，并且之后和另外两名学长一起讨论一下。

## RM 组长

科研的故事暂时先讲到这里，接下来还是要花开两朵各表一支，讲讲其他的事情。就像上集说到的一样，我在 RM 里面已经成功担任了视觉组组长，也就承担了招新的工作。这一部分详细的故事在 RM 回忆录里面有说，在这里也就挑一些和比赛不太相关的事情来讲。

当时相较于之前的培训，我更加青睐于制作一系列的更合理的内容，将培训的知识和考核的内容结合在一起，所以也录制了一系列的视频，同时花了不少时间来去做准备。

与此同时，我依然展现了积极水群的品质，在新生来了的一段时间内，在新生群里面和大家处好关系，也因此认识了不少同学。在这里面可以说我加了不少大一同学的好友，也和一些目前在他们年级中影响力比较大的同学聊过一些，并且通过对于 RM 的宣传，将一些同学招募到了视觉组里面。

整个这一次的培训，总体上来说都显得我十分仁慈，没有做很高强度的抗压，而且最后在筛选的时候也没有非常严格，导致最后还有不少同学剩了下来。因为后面没有任务去给他们布置，使得这些人的积极性下滑，但这就又是后话了。

这一次主要是招募了两名让我印象比较深刻的同学，是我这个年级的同学，LXW，另外一个则是比我小一年的学弟，QZZ。QZZ 可以说是我在西交见过最具天赋的学弟了，估计在科研上的速度说不定可以超过我，后来他在大一下的时候就进入了课题组，并且参加了很多课题的科研，但是遗憾的是，他并没有主动去争取一些主导课题的地位，导致现在属于自己的工作还没有开始进行。按照常理来说，在西交的课题组中进行科研，产出的是正常且不是特别有影响力的工作，往往比较难以一次就中稿，因此他的才华是不是会被埋没，也就未可知了，说不定也不能超过我的论文发表速度。至于 LXW，那段时间大概我会把他视作我的朋友之一，这个人具有一些工程能力，但是课内成绩很低，也并没有科研相关的志向，可以理解为正常的技术爱好者类型的学生，因此我也推荐他来这个比赛去获得加分，这边的需求和他的能力也正好匹配。然而事实上是，我这个人通常与人相处存在一定的距离感，而 LXW 有的时候不打招呼就用我的东西或者吃我的零食，这实在是让我心生膈应，尽管大多数时候他还是作为一个好的朋友存在的。

讲实话，我在社团里面一直扮演的是一个亲民的角色，并非是一个铁血的领导者，导致了后面视觉组一些同学并不怎么做事情，当然最后而言，视觉组还是完成了大多数的目标，虽然因为一些客观问题没有发挥好，但是我认为还是达到了我的预期。

## 科研之二

继续回到科研这一边，毕竟在整个大二生活中，除了正常的学习，就只剩下了参加 RM 以及科研。作为一种安全感的提供，以及对于社交的懒惰，我将社交圈缩小，并且大多数时候只和乐小姐一起，而其他的社交主要集中在了绿群的网上交流。

这些事情其实在第一次的周记里面都已经说过一些了，但是我还是愿意再讲一次。在老师给了我这篇论文之后，虽然说我之前自己已经有了很多相关的实践，但是正式的进行科研工作还是第一次，第二天我就在自己的电脑上下载了数据集并且进行了训练，将论文的成果进行了复现，并且大概将论文的思路和代码都看懂了。

在和老师以及两位师兄讨论的时候，我当时大概提出了自己的见解，对于论文 MCF：Mutual Correction Framework for Semi-Supervised Medical Image Segmentation，本身是在通过两个不同的网络之间的差异来进行半监督学习，从我当时的视角来看，半监督学习在这个语境下面，关键点就是如何维持两个模型之间的多样性。准确地说多个模型在这种协同训练的范式下，因为在此之间通过伪标签建立的损失，所以很快就会具有相同的表征，从而让伪标签不会太有意义。

当时其实我很快就想出来了第一个方法，其实也很显然，我只需要让模型迭代的速度慢下来，保留某一个模型的备份，从而模型依然具有之前的一些多样性的表征，一个明显的方法就是通过 Mean Teacher 来做这个事情。第一次的程序简单粗暴，我在原来协同训练的两个模型的基础上，额外增加了两个教师模型，他们不会在推理的时候使用，只提供伪标签，不参与反向传播。这样一个简单的框架，因为变得复杂，显而易见的达到了 SOTA，但是却缺乏创新性，并不理想。

在之后的一次组会中，我忽然灵光一现，想到了另一个切入点，也就是从模型的不平衡性角度来入手。在 MCF 里面有一个大概率不是原创性的设计，但是因为没有做相关的调查，他们也没有引用，也就不进行追根溯源了，大概的意思就是在协同训练的时候，比较两个模型在有监督数据中的性能，并且将性能高的模型作为教师提供伪标签，从而实现一种动态切换的教师学生关系。这种设计的好处是显然的，可以简单直接的 filter 掉一些不好的伪标签，虽然说在有监督数据上的性能并不是客观准确的，但是至少有一些参考价值。然而这也引发一种担忧，也就是假如我用两个不同结构的模型（MCF 的设计），这两个模型的性能天然就不一样，按理来说好一些的模型具有更大的获得性能的潜力，但是却因为他一直提供伪标签，而导致只具有更少的使用无监督数据的机会，最后让两个模型都趋于平庸。

那么有没有一种东西可以改变模型的性能，而且不是和模型或者损失函数绑定在一起，并且可以灵活变化的呢？假如可以找到这样一个属性，那就可以让模型之间进行平衡的切换，并且建立稳定的多样性，这种多样性不是一个模型始终领先另一个模型，或者在多数情况下领先，是两个模型平等的进行切换，从而都可以充分利用到无监督数据。答案显而易见，也就是迭代次数。

我在组会中提出了这个想法之后，老师也认为有一些希望，所以会之后我很快就搭建出来了第一版的代码框架，两个模型会进行交替训练，在后续的命名中，最后选择了 progressive 来形容这个现象，然后在数据集上进行了训练和测试，超过了 SOTA 两个点。

那时候大概从我开始科研过了两个多星期，而且距离 CVPR 截止大概还有四个星期，我自然是喜欢做很大的梦的，所以找老师说了一下这个现象，并且和老师聊了聊，决定投一下试一试。当天我就写了一些论文，主要还是仿照 MCF 的写作思路，现在来看这种思路十分奇怪，是从对另一篇论文的攻击开始的，也就是指出他的错误，并且说自己可以避免这一错误。我的论文仿照了这种写法，也指出了 MCF 的问题，并且提出了自己的解决方法以及贡献点，给老师看了之后被光速驳回了。毕竟 MCF 驳斥的是一篇知名的论文，所以说还站得住脚，但是假如我去驳斥 MCF，也就成为了一篇名不见经传的工作的后续改进了，自然也就差了点意思。接下来老师跟我讲了新的思路，怎么去组织这个故事线，然后我就开始一边跑实验一边画图一边写论文了。

周老师在我的整个科研经历里面，主要还是起到了口头指导以及论文写作上一些帮助的作用，然而并没有非常手把手的对我进行协助，然而我并不认为这有问题。事实上一方面老师比较忙，另一方面与老师的交流，我已经能学到许多东西，就在后面也会体现出来。

整体的论文思路改成了周老师认为比较合理的走向，也就是自顶向下的去讲述这个故事，从这个领域开始说，然后说为什么很重要，之前一些著名的工作以及最近的工作做了很多探索，但是还有缺陷，而我们的工作解决了这个缺陷。这种论文写作的思路的核心在于，不去讲述思考的过程，而是直接指出解决了问题，让方法有一种浑然天成的感觉。具体来说，我们不会说对于这个现象，观察到了某些结果，认为这是某种原因，并且构建了某个模块，甚至和其他模块进行了比较，选择了最合理的；而是直接说对于这个问题，我们设计了这个模块，从而在这个现象中避免这些结果，而且经过实验还发现我们的这个模块比别的模块要好。这种故事讲述顺序的颠倒，成就了自顶向下和自底向上的两种方式，而我通常更喜欢前者。

在跑了大量的实验，把之前的工作都亲自在服务器上重新跑了之后，我给出了论文的主要表格，同时因为缺乏一些贡献点，将 MCF 里面的 tricks 进行了一些包装，并且讲述了在我的框架下的效果，作为贡献点之一，并且进行了投稿。

投稿结束的几天，可以说那时候就是春风得意马蹄疾，自诩为是某一种天才少年，年纪轻轻就可以以第一作者投稿 CVPR，但是结果确实让我清醒了不少，311。

可以说两位审稿人都给出了十分负面的评价，一位指出了我使用的两个模块本质上和 MCF 相同，两个人更多的还是对性能进行了质疑。具体来说，我在测试的过程中，把每一个模型都在统一的环境里面进行了测试，同时还把 batch size 进行了对齐，但是确确实实有不少模型，在这些测试里面的性能十分差，甚至和原文相差了十多个点，在后续的分析里面，我其实注意到这个现象，大概原因是，我 follow 了 MCF 的 K 折划分，而之前的工作都是在 UAMT 的单一划分中进行的，我不太清楚这个划分是不是精心 pick 了一些数据，但是反正就差距很大，那些模型在这个好的划分上提了很多的点，虽然和原文中讲的还有不少差距。当然除此之外，论文内容也有很多没有仔细看清楚，包括残留了一些之前的模型命名，以及一些符号的使用错误，所以以毫无疑问的转投了 ECCV。

我总结了一下问题，大概就是几点，一方面我不能用自己测试的数据，而是需要使用他们自己汇报的内容，这是比较重要的第一点，也就是说我需要在他们或许有一定造假嫌疑的数据中获得 SOTA，这带来了比较大的调参工作；一方面模型的方法还需要一些调整，不能和 MCF 完全一致，虽然说它里面的这两个方法也大概率不是原创性的，毕竟他主打的其实是异构模型的协同训练，但是至少将这两个方法讲出了自己的故事，我也有必要做一些调整，无论是在方法上还是在故事上；最后就是论文的写作还需要提升，ECCV 的时间其实不算很充裕，但是也给了我一定的润色时间。

于是这条路又一次开始了，我现是在这些数据集上进行了调参以及消融实验的记录，之后将两个小的模块进行了略微的修改，将整个的故事的侧重点更多地放在 progressive 的模块设计以及故事，而去弱化这两个为了撑住贡献点而保留的模块